getwd()
git checkout master
library(git2r)
git checkout master
git status
getwd()
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
path <- "/Users/Katja/Box Sync/PhD Lund Katja/Sequencing/PacBio AMF/Sequencing data AMF/dada2/AMF_DOK trial/samples"
list.files(path) #listing all files in the path
rm(path)
path_fastq <- "/Users/Katja/Box Sync/PhD Lund Katja/Sequencing/PacBio AMF/Sequencing data AMF/dada2/AMF_DOK trial/samples"
list.files(path_fastq) #listing all files in the path
fns <- sort(list.files(path_fastq, pattern=".fq", full.names = TRUE)) #selection of all fastq files
sample.names <- sapply(strsplit(basename(fns), "_"), `[`, 2)
print(sample.names)
getwd()
plotQualityProfile(fns[1:6])
#clean everything
rm(list=ls())
#load libraries
library(dada2); packageVersion("dada2")
library(DECIPHER); packageVersion("DECIPHER")
library(phyloseq); packageVersion("phyloseq")
path_fastq <- "/Users/Katja/Box Sync/PhD Lund Katja/Sequencing/PacBio AMF/Sequencing data AMF/dada2/AMF_DOK trial/samples"
list.files(path_fastq) #listing all files in the path
fns <- sort(list.files(path_fastq, pattern=".fq", full.names = TRUE)) #selection of all fastq files
sample.names <- sapply(strsplit(basename(fns), "_"), `[`, 2)
print(sample.names)
plotQualityProfile(fns[1:6])
plotQualityProfile(fns[7:12])
plotQualityProfile(fns[13:18])
plotQualityProfile(fns[19:24])
plotQualityProfile(fns[25:30])
plotQualityProfile(fns[31:36])
plotQualityProfile(fns[37:42])
plotQualityProfile(fns[43:48])
#tiff format for plot
tiff('rplot1-6.tiff', res=300,units='px', width=2100, height=1800,  pointsize=6)
plotQualityProfile(fnFs[1:6])
#tiff format for plot
tiff('rplot1-6.tiff', res=300,units='px', width=2100, height=1800,  pointsize=6)
plotQualityProfile(fns[1:6])
dev.off()
#tiff format for plot
tiff('rplot1-6.tiff', 'rplot7-12.tiff', res=300,units='px', width=2100, height=1800,  pointsize=6)
#inspect length distribution of sequences to determine how to filter the sequences
length_fns <- lapply(path_fastq, function(fn) nchar(getSequences(fn)))
length <- do.call(c, length_fns)
hist(length, 100)
mean(length); median(length)
min(length); max(length)
#place filtered files in filtered/ subdirectory
filt_path <- file.path(path_fastq, "filtered")
filt_fn <- file.path(path_fastq, "filtered", paste0(sample.names, "_filt.fq.gz"))
names(filt_fn) <- sample.names
filt_out <- filterAndTrim(fnFs_new, filtFs_new, minQ=2, minLen=1300, maxLen=1800, maxN=0, rm.phix=FALSE, maxEE=2, multithread = FALSE)
filt_out <- filterAndTrim(fns, filtFs_new, minQ=2, minLen=1300, maxLen=1800, maxN=0, rm.phix=FALSE, maxEE=2, multithread = FALSE)
rm(filt_fn)
#place filtered files in filtered/ subdirectory
filt_path <- file.path(path_fastq, "filtered")
filt_fns <- file.path(path_fastq, "filtered", paste0(sample.names, "_filt.fq.gz"))
names(filt_fn) <- sample.names
#place filtered files in filtered/ subdirectory
filt_path <- file.path(path_fastq, "filtered")
filt_fns <- file.path(path_fastq, "filtered", paste0(sample.names, "_filt.fq.gz"))
names(filt_fns) <- sample.names
filt_out <- filterAndTrim(fns, filt_fns, minQ=2, minLen=1300, maxLen=1800, maxN=0, rm.phix=FALSE, maxEE=2, multithread = FALSE)
print("Sequences filtered")
print(filt_out)
getwd()
write.csv(filt_out, "/Users/Katja/Box Sync/PhD Lund Katja/Sequencing/PacBio AMF/Sequencing data AMF/dada2/AMF_DOK trial/PacBio_AMF_workflow/results_dada2/filtered_seq.csv")
# Inspect length distribution of filtered sequences
length_fns_filt <- lapply(filt_path, function(fn) nchar(getSequences(fn)))
length_filt <- do.call(c, length_fns_filt)
hist(length_filt, 100)
mean(length_filt); median(length_filt)
derep <- derepFastq(filt_fns, verbose=TRUE)
names(derep) <- sample.names
derep
err <- learnErrors(derep, errorEstimationFunction = PacBioErrfun, BAND_SIZE = 32,
multithread = TRUE, verbose = TRUE)
print(filt_out
)
derep
names(derep)
err <- learnErrors(derep, errorEstimationFunction = PacBioErrfun, BAND_SIZE = 32,
multithread = TRUE, verbose = TRUE)
plotErrors(err)
plotErrors(err, nominalQ=TRUE)
#separate true biological sequences from errors
dada_dd <- dada(derep, err = err, BAND_SIZE = 32, multithread = TRUE, verbose = TRUE, pool = "pseudo")
dada_dd[[1]] #only for the first sample
seqtab <- makeSequenceTable(dada_dd); dim(seqtab)
table(nchar(getSequences(seqtab))) #distibution of sequence lengths
path_rds <- "RDS/"
saveRDS(seqtab, file.path(path_rds, "asv_table.rds"))
saveRDS(seqtab, file.path(path_rds, "asv_table.rds"))
rm(path_rds)
seqtab.nochim <- removeBimeraDenovo(seqtab, method="consensus", multithread=TRUE, verbose=TRUE)
dim(seqtab.nochim)
sum(seqtab.nochim)/sum(seqtab)
#what proportion of the sequence variants are chimeras
1-sum(seqtab.nochim)/sum(seqtab)  #0.0009238807
#what proportion of the sequence variants are chimeras
sum(seqtab.nochim)/sum(seqtab)
cbind(ccs = prim[,1], primers = prim[,2], filtered = track[,2],
denoised = sapply(dada_dd, function(x) sum(x$denoised)), nonchimeric = apply(seqtab.nochim, 1, sum),
retained = apply(seqtab.nochim, 1, sum)/prim[,1])
cbind(filtered = track[,2],
denoised = sapply(dada_dd, function(x) sum(x$denoised)), nonchimeric = apply(seqtab.nochim, 1, sum),
retained = apply(seqtab.nochim, 1, sum)/prim[,1])
cbind(filtered = filt_out[,2],
denoised = sapply(dada_dd, function(x) sum(x$denoised)), nonchimeric = apply(seqtab.nochim, 1, sum),
retained = apply(seqtab.nochim, 1, sum)/prim[,1])
cbind(filtered = filt_out[,2],
denoised = sapply(dada_dd, function(x) sum(x$denoised)), nonchimeric = apply(seqtab.nochim, 1, sum),
retained = apply(seqtab.nochim, 1, sum))
getN <- function(x) sum(getUniques(x))
track <- cbind(filt_out, sapply(dada_dd, getN), rowSums(seqtab.nochim))
colnames(track) <- c("input", "filtered", "denoised", "nonchim")
rownames(track) <- sample.names
head(track)
class(track)
print(track)
#seqtab.nochim file is the final file, samples and sequences that represents ASVs
#rarefied species richness
rarecurve(seqtab.nochim)
#distribution of sequence length
plot(sort(unname(rowSums(seqtab.nochim))))
library(vegan)
rarecurve(seqtab.nochim)
library(vegan); packageVersion("vegan")
#give our sequence headers more manageable names (ASV_1, ASV_2...) and write out a FASTA of our ASV seqs
asv_seqs <- colnames(seqtab.nochim)
asv_headers <- vector(dim(seqtab.nochim)[2], mode = "character")
for (i in 1:dim(seqtab.nochim)[2]) {
asv_headers[i] <- paste(">ASV", i, sep = "_")
}
write(asv_fasta, "/Users/Katja/Box Sync/PhD Lund Katja/Sequencing/PacBio AMF/Sequencing data AMF/dada2/AMF_DOK trial/PacBio_AMF_workflow/results_dada2/ASVs_processed.fasta")
asv_fasta <- c(rbind(asv_headers, asv_seqs))
write(asv_fasta, "/Users/Katja/Box Sync/PhD Lund Katja/Sequencing/PacBio AMF/Sequencing data AMF/dada2/AMF_DOK trial/PacBio_AMF_workflow/results_dada2/ASVs_processed.fasta")
asv_tab <- t(seqtab.nochim)
row.names(asv_tab) <- sub(">", "", asv_headers)
write.table(asv_tab, "/Users/Katja/Box Sync/PhD Lund Katja/Sequencing/PacBio AMF/Sequencing data AMF/dada2/AMF_DOK trial/results/ASVs_counts.csv", sep = ",", quote = FALSE, col.names = NA)
write.table(asv_tab, "/Users/Katja/Box Sync/PhD Lund Katja/Sequencing/PacBio AMF/Sequencing data AMF/dada2/AMF_DOK trial/PacBio_AMF_workflow/results_dada2/ASVs_counts.csv", sep = ",", quote = FALSE, col.names = NA)
asv_tab <- (seqtab.nochim)
row.names(asv_tab) <- sub(">", "", asv_headers)
col.names(asv_tab) <- sub(">", "", asv_headers)
colnames(asv_tab) <- sub(">", "", asv_headers)
write.table(asv_tab, "/Users/Katja/Box Sync/PhD Lund Katja/Sequencing/PacBio AMF/Sequencing data AMF/dada2/AMF_DOK trial/PacBio_AMF_workflow/results_dada2/ASVs_counts.csv", sep = ",", quote = FALSE, col.names = NA)
load("/Users/Katja/Box Sync/PhD Lund Katja/Sequencing/PacBio AMF/Sequencing data AMF/dada2/AMF_DOK trial/reference databases/UNITE_v2020_February2020.RData")
View(trainingSet)
#you have to set seed every time you want to get a reproducible random result
set.seed(NULL) #return to the original state by unsetting the seed
taxonomy_unite <- DNAStringSet(getSequences(seqtab.nochim)) # Create a DNAStringSet from the ASVs
taxonomy_unite
View(taxonomy_unite)
taxonomy_unite <- RemoveGaps(taxonomy_unite)
View(taxonomy_unite)
#assign classification
ids <- IdTaxa(taxonomy_unite, trainingSet, strand="both", threshold=50, bootstraps=100, processors=NULL, verbose=FALSE)
write(track, "/Users/Katja/Box Sync/PhD Lund Katja/Sequencing/PacBio AMF/Sequencing data AMF/dada2/AMF_DOK trial/PacBio_AMF_workflow/results_dada2/summary_seq.csv")
write.csv(track, "/Users/Katja/Box Sync/PhD Lund Katja/Sequencing/PacBio AMF/Sequencing data AMF/dada2/AMF_DOK trial/PacBio_AMF_workflow/results_dada2/summary_seq.csv")
ids
c("kingdom", "phylum", "class", "order", "family", "genus", "species")
library(dada2)
library(DECIPHER)
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
#assign classification
ids <- IdTaxa(taxonomy_unite, trainingSet, strand="both", threshold=50, bootstraps=100, processors=NULL, verbose=FALSE)
View(ids) #results
ranks <- c("Kingdom", "Phylum", "Class", "Order", "Family", "Genus", "Species") # ranks of interest
View(ranks)
taxid <- t(sapply(ids, function(x) {
m <- match(ranks, x$rank)
taxa <- x$taxon[m]
taxa[startsWith(taxa, "unclassified_")] <- NA
taxa
}))
taxid
colnames(taxid) <- ranks; rownames(taxid) <- getSequences(seqtab.nochim)
plot(ids, trainingSet)
TAX = tax_table(taxid)
library(phyloseq)
TAX = tax_table(taxid)
TAX
rm(TAX)
write.csv(taxid, "/Users/Katja/Box Sync/PhD Lund Katja/Sequencing/PacBio AMF/Sequencing data AMF/dada2/AMF_DOK trial/PacBio_AMF_workflow/results_dada2/taxonomy_unite2020.csv")
sapply(ids, function(x) {
w<-which(x$rank=="Phylum")
if(length(w) !=1) {
"unknown"
} else {
x$taxon[w]
}
})
View(trainingSet)
set.seed(NULL) #return to the original state by unsetting the seed
set.seed(62)
taxonomy_unite <- DNAStringSet(getSequences(seqtab.nochim)) # create a DNAStringSet from the ASVs
taxonomy_unite
plot(ids) #pie chart showing the relative abundance of the taxonomic groups assigned to test sequences
plot(ids) #pie chart showing the relative abundance of the taxonomic groups assigned to test sequences
sapply(ids,
function (id) {
paste(id$taxon,
" (",
round(id$confidence, digits=1),
"%)",
sep="",
collapse="; ")
})
sapply(ids,
function(x)
paste(x$taxon,
collapse=";"))
asv_tab
hist(length, 100)
plot(sort(unname(rowSums(length))))
hist(length_filt, 100)
hist(length, 50)
hist(length, 200)
hist(length, 50)
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
filt_out <- filterAndTrim(fns, filt_fns, minQ=2, minLen=1300, maxLen=1700, maxN=0, rm.phix=FALSE, maxEE=2, multithread = FALSE)
library(dada2); packageVersion("dada2") #1.14.0
library(DECIPHER); packageVersion("DECIPHER") #2.14.0
library(phyloseq); packageVersion("phyloseq") #1.30.0
library(vegan); packageVersion("vegan") #2.5.6
length_fns
View(length_fns)
max(length_fns)
length
median(length)
filt_out <- filterAndTrim(fns, filt_fns, minQ=2, minLen=1300, maxLen=1700, maxN=0, rm.phix=FALSE, maxEE=2, multithread = FALSE)
print(filt_out)
filt_out <- filterAndTrim(fns, filt_fns, minQ=2, minLen=1300, maxLen=1700, maxN=0, rm.phix=FALSE, maxEE=3, multithread = FALSE)
print(filt_out)
filt_out <- filterAndTrim(fns, filt_fns, minQ=2, minLen=1400, maxLen=1700, maxN=0, rm.phix=FALSE, maxEE=3, multithread = FALSE)
filt_out
filt_out <- filterAndTrim(fns, filt_fns, minQ=2, minLen=1400, maxLen=1700, maxN=0, rm.phix=FALSE, maxEE=2, multithread = FALSE)
filt_out
filt_out <- filterAndTrim(fns, filt_fns, minQ=2, minLen=1300, maxLen=1700, maxN=0, rm.phix=FALSE, maxEE=3, multithread = FALSE)
filt_out
length_fns_filt <- lapply(filt_path, function(fn) nchar(getSequences(fn)))
length_fns_filt <- lapply(filt_path, function(fn) nchar(getSequences(fn)))
length_filt <- do.call(c, length_fns_filt)
hist(length_filt, 100)
mean(length_filt); median(length_filt)
hist(length_filt, 100)
filt_out <- filterAndTrim(fns, filt_fns, minQ=2, minLen=1350, maxLen=1700, maxN=0, rm.phix=FALSE, maxEE=3, multithread = FALSE)
filt_out
#csv file containing number of input and output/filtered sequences
write.csv(filt_out, "/Users/Katja/Box Sync/PhD Lund Katja/Sequencing/PacBio AMF/Sequencing data AMF/dada2/AMF_DOK trial/PacBio_AMF_workflow/results_dada2/filtered_seq.csv")
length_fns_filt <- lapply(filt_path, function(fn) nchar(getSequences(fn)))
length_filt <- do.call(c, length_fns_filt)
hist(length_filt, 100)
mean(length_filt); median(length_filt)
#collapse identical sequences
derep <- derepFastq(filt_fns, verbose=TRUE)
derep
#collapse identical sequences
derep <- derepFastq(filt_fns, verbose=TRUE)
names(derep) <- sample.names #name the derep-class objects by the sample names
#error rates for each possible transition
set.seed(100)
err <- learnErrors(derep, errorEstimationFunction = PacBioErrfun, BAND_SIZE = 32,
multithread = TRUE, verbose = TRUE)
plotErrors(err)
plotErrors(err, nominalQ=TRUE) #red line shows the error rates, the estimated error rates (black line) are a good fit to the observed rates (points), error rates should drop with the increased quality
#infer the sequence variants in each sample
#separate true biological sequences from errors
dada_dd <- dada(derep, err = err, BAND_SIZE = 32, multithread = TRUE, verbose = TRUE, pool = "pseudo") #number of true sequences
dada_dd[[1]] #check only the first sample
seqtab <- makeSequenceTable(dada_dd); dim(seqtab) #48 991
table(nchar(getSequences(seqtab))) #distibution of sequence lengths
min(seqtab)
seqtab.nochim <- removeBimeraDenovo(seqtab, method="consensus", multithread=TRUE, verbose=TRUE)
dim(seqtab.nochim) #48 981
#what proportion of the sequence variants are chimeras
sum(seqtab.nochim)/sum(seqtab)
1-sum(seqtab.nochim)/sum(seqtab)  #0.004301049
getN <- function(x) sum(getUniques(x))
track <- cbind(filt_out, sapply(dada_dd, getN), rowSums(seqtab.nochim))
colnames(track) <- c("input", "filtered", "denoised", "nonchim")
rownames(track) <- sample.names
print(track)
class(track) #it is a matrix
#save summary
write.csv(track, "/Users/Katja/Box Sync/PhD Lund Katja/Sequencing/PacBio AMF/Sequencing data AMF/dada2/AMF_DOK trial/PacBio_AMF_workflow/results_dada2/summary_seq.csv")
#distribution of sequence length
plot(sort(unname(rowSums(seqtab.nochim))))
plot(ids, trainingSet)
#species richness
rarecurve(seqtab.nochim)
rarecurve(seqtab.nochim)
#give our sequence headers more manageable names (ASV_1, ASV_2...) and write out a FASTA of our ASV seqs
asv_seqs <- colnames(seqtab.nochim)
asv_headers <- vector(dim(seqtab.nochim)[2], mode = "character")
for (i in 1:dim(seqtab.nochim)[2]) {
asv_headers[i] <- paste(">ASV", i, sep = "_")
}
asv_fasta <- c(rbind(asv_headers, asv_seqs))
asv_fasta
write(asv_fasta, "/Users/Katja/Box Sync/PhD Lund Katja/Sequencing/PacBio AMF/Sequencing data AMF/dada2/AMF_DOK trial/PacBio_AMF_workflow/results_dada2/ASVs_processed.fasta")
asv_tab <- (seqtab.nochim)
colnames(asv_tab) <- sub(">", "", asv_headers)
write.table(asv_tab, "/Users/Katja/Box Sync/PhD Lund Katja/Sequencing/PacBio AMF/Sequencing data AMF/dada2/AMF_DOK trial/PacBio_AMF_workflow/results_dada2/ASVs_counts.csv", sep = ",", quote = FALSE, col.names = NA)
set.seed(NULL) #return to the original state by unsetting the seed
set.seed(62)
taxonomy_unite <- DNAStringSet(getSequences(seqtab.nochim)) # create a DNAStringSet from the ASVs
taxonomy_unite <- RemoveGaps(taxonomy_unite)
View(taxonomy_unite)
#assign classification
ids <- IdTaxa(taxonomy_unite, trainingSet, strand="both", threshold=50, bootstraps=100, processors=NULL, verbose=FALSE)
View(ids) #results
plot(ids) #pie chart showing the relative abundance of the taxonomic groups assigned to test sequences
ranks <- c("Kingdom", "Phylum", "Class", "Order", "Family", "Genus", "Species") # ranks of interest
View(ranks)
taxid <- t(sapply(ids, function(x) {
m <- match(ranks, x$rank)
taxa <- x$taxon[m]
taxa[startsWith(taxa, "unclassified_")] <- NA
taxa
}))
colnames(taxid) <- ranks; rownames(taxid) <- getSequences(seqtab.nochim)
rownames(taxid)
asv_tab
colnames(taxid) <- ranks; rownames(taxid) <- getSequences(asv_tab)
rownames(taxid)
write.csv(taxid, "/Users/Katja/Box Sync/PhD Lund Katja/Sequencing/PacBio AMF/Sequencing data AMF/dada2/AMF_DOK trial/PacBio_AMF_workflow/results_dada2/taxonomy_unite2020.csv")
colnames(taxid)
taxid
?IdTaxa
ids
ids$rank
phylum <- sapply(ids, function(x) {
w<-which(x$rank=="phylum")
if(length(w) !=1) {
"unknown"
} else {
x$taxon[w]
}
})
table(phylum)
rm(phylum)
output <- sapply(ids,
function (id) {
paste(id$taxon,
" (",
round(id$confidence, digits=1),
"%)",
sep="",
collapse="; ")
})
tail(output)
taxa.print <- taxid
taxa.print
load("/Users/Katja/Box Sync/PhD Lund Katja/Sequencing/PacBio AMF/Sequencing data AMF/dada2/AMF_DOK trial/reference databases/UNITE_v2019gz.RData")
taxonomy_unite <- DNAStringSet(getSequences(seqtab.nochim)) # create a DNAStringSet from the ASVs
taxonomy_unite <- RemoveGaps(taxonomy_unite)
#assign classification
ids <- IdTaxa(taxonomy_unite, trainingSet, strand="both", threshold=50, bootstraps=100, processors=NULL, verbose=FALSE)
taxid <- t(sapply(ids, function(x) {
m <- match(ranks, x$rank)
taxa <- x$taxon[m]
taxa[startsWith(taxa, "unclassified_")] <- NA
taxa
}))
colnames(taxid) <- ranks; rownames(taxid) <- getSequences(asv_tab)
write.csv(taxid, "/Users/Katja/Box Sync/PhD Lund Katja/Sequencing/PacBio AMF/Sequencing data AMF/dada2/AMF_DOK trial/PacBio_AMF_workflow/results_dada2/taxonomy_unite2020.csv")
load("/Users/Katja/Box Sync/PhD Lund Katja/Sequencing/PacBio AMF/Sequencing data AMF/dada2/AMF_DOK trial/reference databases/UNITE_v2020_February2020.RData")
set.seed(NULL) #return to the original state by unsetting the seed
set.seed(62)
taxonomy_unite <- DNAStringSet(getSequences(seqtab.nochim)) # create a DNAStringSet from the ASVs
taxonomy_unite <- RemoveGaps(taxonomy_unite)
#assign classification
ids <- IdTaxa(taxonomy_unite, trainingSet, strand="both", threshold=50, bootstraps=100, processors=NULL, verbose=FALSE)
ranks <- c("Kingdom", "Phylum", "Class", "Order", "Family", "Genus", "Species") # ranks of interest
View(ranks)
ranks <- c("kingdom", "phylum", "class", "order", "family", "genus", "species") # ranks of interest
View(ranks)
taxid <- t(sapply(ids, function(x) {
m <- match(ranks, x$rank)
taxa <- x$taxon[m]
taxa[startsWith(taxa, "unclassified_")] <- NA
taxa
}))
colnames(taxid) <- ranks; rownames(taxid) <- getSequences(asv_tab)
write.csv(taxid, "/Users/Katja/Box Sync/PhD Lund Katja/Sequencing/PacBio AMF/Sequencing data AMF/dada2/AMF_DOK trial/PacBio_AMF_workflow/results_dada2/taxonomy_unite2020.csv")
rm(taxa.print)
